{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課程目標:\n",
    "了解Keras 函數式 API 的使用 <br />\n",
    "# 範例重點:\n",
    "了解函數式 API 的彈性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "#主要輸入接收新聞標題本身，即一個整數序列（每個整數編碼一個詞）。\n",
    "#這些整數在1 到10,000 之間（10,000 個詞的詞彙表），且序列長度為100 個詞\n",
    "#宣告一個 NAME 去定義Input\n",
    "main_input = Input(shape = (100,), dtype = 'int32', name = 'main_input')\n",
    "\n",
    "# Embedding 層將輸入序列編碼為一個稠密向量的序列，\n",
    "# 每個向量維度為 512。\n",
    "x = Embedding(output_dim = 512, input_dim = 10000, input_length = 100)(main_input)\n",
    "\n",
    "# LSTM 層把向量序列轉換成單個向量，\n",
    "# 它包含整個序列的上下文信息\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#插入輔助損失，使得即使在模型主損失很高的情況下，LSTM 層和Embedding 層都能被平穩地訓練\n",
    "auxiliary_output = Dense(1, activation = 'sigmoid', name = 'aux_output')(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輔助輸入數據與LSTM 層的輸出連接起來，輸入到模型\n",
    "import keras\n",
    "auxiliary_input = Input(shape = (5,), name = 'aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# 堆疊多個全連接網路層\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "#作業解答: 新增兩層\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "\n",
    "# 最後添加主要的邏輯回歸層\n",
    "main_output = Dense(1, activation = 'sigmoid', name = 'main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 宣告 MODEL API, 分別採用自行定義的 Input/Output Layer\n",
    "model = Model(inputs = [main_input, auxiliary_input], outputs = [main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 20:52:57.765306 17328 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0704 20:52:57.795892 17328 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0704 20:52:57.803911 17328 deprecation.py:323] From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = {'main_output' : 'binary_crossentropy', 'aux_output' : 'binary_crossentropy'},\n",
    "             loss_weights = {'main_output' : 1. , 'aux_output' : 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 512)     5120000     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           69760       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 37)           0           lstm_2[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           2432        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           4160        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           4160        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            65          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            33          lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,204,770\n",
      "Trainable params: 5,204,770\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "建立一個網路模型 <br />\n",
    "# 作業重點:\n",
    "請修改 Name 中, 自定義的 Layer 名稱 <br />\n",
    "<br />\n",
    "增加一層全連階層 <br />\n",
    "<br />\n",
    "宣告 MODEL API, 分別採用自行定義的 Input/Output Layer <br />\n",
    "<br />\n",
    "model.summary 查看 Layers stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x train shape : (60000, 28, 28) \n",
      " y train shape : (60000,) \n",
      " x test shape : (10000, 28, 28) \n",
      " y test shape : (10000,) \n"
     ]
    }
   ],
   "source": [
    "print(f' x train shape : {x_train.shape} ')\n",
    "print(f' y train shape : {y_train.shape} ')\n",
    "print(f' x test shape : {x_test.shape} ')\n",
    "print(f' y test shape : {y_test.shape} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)\n",
    "\n",
    "print(y_train_onehot.shape)\n",
    "print(y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_train, y_train_onehot, test_size = 0.5, random_state = 2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input( shape = (28,28,1), dtype = np.uint8, name = 'main_input')\n",
    "x = Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu')(main_input)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "one_layer_output = Dense(10, activation = 'softmax', name = 'first_output')(x)\n",
    "\n",
    "second_Input( shape = (10, ), dtype = np.int32, name = 'second_input')\n",
    "x = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
