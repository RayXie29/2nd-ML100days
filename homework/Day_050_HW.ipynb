{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例 : (Kaggle)房價預測\n",
    "分數以網站評分結果為準, 請同學實際將提交檔(*.csv)上傳試試看<br />\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submit<br /> \n",
    "\n",
    "\n",
    "## [教學目標]\n",
    "以下用房價預測資料, 觀查堆疊泛化 (Stacking) 的寫法與效果<br />\n",
    "\n",
    "\n",
    "## [範例重點]\n",
    "觀察堆疊泛化的準確度 , 是否比單一模型準確度為高 <br />\n",
    "與前一日的混合泛化結果相比呢?<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "3         Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n",
       "4         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0       2    2008        WD         Normal  \n",
       "1         NaN       0       5    2007        WD         Normal  \n",
       "2         NaN       0       9    2008        WD         Normal  \n",
       "3         NaN       0       2    2006        WD        Abnorml  \n",
       "4         NaN       0      12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "data_path = './data/'\n",
    "train_df = pd.read_csv(data_path + 'train.csv')\n",
    "test_df = pd.read_csv(data_path + 'test.csv')\n",
    "\n",
    "train_label = train_df.SalePrice\n",
    "train_label = np.log1p(train_label.values)\n",
    "train_df = train_df.drop(['Id','SalePrice'], axis = 1)\n",
    "test_ids = test_df['Id']\n",
    "test_df = test_df.drop(['Id'], axis = 1)\n",
    "\n",
    "total_df = pd.concat([train_df, test_df], axis = 0)\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing ratio in MSZoning : 0.1370332305584104 %\n",
      " Missing ratio in LotFrontage : 16.649537512846866 %\n",
      " Missing ratio in Alley : 93.21685508735868 %\n",
      " Missing ratio in Utilities : 0.0685166152792052 %\n",
      " Missing ratio in Exterior1st : 0.0342583076396026 %\n",
      " Missing ratio in Exterior2nd : 0.0342583076396026 %\n",
      " Missing ratio in MasVnrType : 0.8221993833504625 %\n",
      " Missing ratio in MasVnrArea : 0.7879410757108599 %\n",
      " Missing ratio in BsmtQual : 2.774922918807811 %\n",
      " Missing ratio in BsmtCond : 2.8091812264474134 %\n",
      " Missing ratio in BsmtExposure : 2.8091812264474134 %\n",
      " Missing ratio in BsmtFinType1 : 2.7064063035286057 %\n",
      " Missing ratio in BsmtFinSF1 : 0.0342583076396026 %\n",
      " Missing ratio in BsmtFinType2 : 2.7406646111682083 %\n",
      " Missing ratio in BsmtFinSF2 : 0.0342583076396026 %\n",
      " Missing ratio in BsmtUnfSF : 0.0342583076396026 %\n",
      " Missing ratio in TotalBsmtSF : 0.0342583076396026 %\n",
      " Missing ratio in Electrical : 0.0342583076396026 %\n",
      " Missing ratio in BsmtFullBath : 0.0685166152792052 %\n",
      " Missing ratio in BsmtHalfBath : 0.0685166152792052 %\n",
      " Missing ratio in KitchenQual : 0.0342583076396026 %\n",
      " Missing ratio in Functional : 0.0685166152792052 %\n",
      " Missing ratio in FireplaceQu : 48.646796848235695 %\n",
      " Missing ratio in GarageType : 5.378554299417608 %\n",
      " Missing ratio in GarageYrBlt : 5.4470709146968135 %\n",
      " Missing ratio in GarageFinish : 5.4470709146968135 %\n",
      " Missing ratio in GarageCars : 0.0342583076396026 %\n",
      " Missing ratio in GarageArea : 0.0342583076396026 %\n",
      " Missing ratio in GarageQual : 5.4470709146968135 %\n",
      " Missing ratio in GarageCond : 5.4470709146968135 %\n",
      " Missing ratio in PoolQC : 99.65741692360398 %\n",
      " Missing ratio in Fence : 80.4385063377869 %\n",
      " Missing ratio in MiscFeature : 96.40287769784173 %\n",
      " Missing ratio in SaleType : 0.0342583076396026 %\n"
     ]
    }
   ],
   "source": [
    "def CheckMissingVals(data):\n",
    "    for col in data.columns:\n",
    "        if np.sum(data[col].isnull()):\n",
    "            print(f' Missing ratio in {col} : {np.sum(data[col].isnull()) / len(data) * 100} %')\n",
    "\n",
    "CheckMissingVals(total_df)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing ratio in MSZoning : 0.1370332305584104 %\n",
      " Missing ratio in LotFrontage : 16.649537512846866 %\n",
      " Missing ratio in Utilities : 0.0685166152792052 %\n",
      " Missing ratio in Exterior1st : 0.0342583076396026 %\n",
      " Missing ratio in Exterior2nd : 0.0342583076396026 %\n",
      " Missing ratio in Electrical : 0.0342583076396026 %\n",
      " Missing ratio in KitchenQual : 0.0342583076396026 %\n",
      " Missing ratio in SaleType : 0.0342583076396026 %\n"
     ]
    }
   ],
   "source": [
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'FireplaceQu', 'FireplaceQu', 'FireplaceQu', \n",
    "            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "             'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'Functional', 'MSSubClass']\n",
    "zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', \n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']\n",
    "\n",
    "for col in none_cols:\n",
    "    total_df[col] = total_df[col].fillna('None')\n",
    "for col in zero_cols:\n",
    "    total_df[col] = total_df[col].fillna(0)\n",
    "\n",
    "CheckMissingVals(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill some part of missing with mode val\n",
    "mode_cols = ['MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType']\n",
    "for col in mode_cols:\n",
    "    total_df[col] = total_df[col].fillna(total_df[col].mode()[0])\n",
    "    \n",
    "# fillna missing vals in LotFrontage with median vals in same Neighborhood\n",
    "total_df['LotFrontage'] = total_df.groupby(['Neighborhood'])['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "\n",
    "total_df = total_df.drop(['Utilities'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckMissingVals(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape total df : (2919, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>TotalSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>2473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0          10       RL         65.0     8450       1      1         3   \n",
       "1           5       RL         80.0     9600       1      1         3   \n",
       "2          10       RL         68.0    11250       1      1         0   \n",
       "3          11       RL         60.0     9550       1      1         0   \n",
       "4          10       RL         84.0    14260       1      1         0   \n",
       "\n",
       "  LandContour LotConfig  LandSlope  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    Inside          0  ...        0      3     4        None   \n",
       "1         Lvl       FR2          0  ...        0      3     4        None   \n",
       "2         Lvl    Inside          0  ...        0      3     4        None   \n",
       "3         Lvl    Corner          0  ...        0      3     4        None   \n",
       "4         Lvl       FR2          0  ...        0      3     4        None   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition TotalSF  \n",
       "0       0       4       2        WD         Normal  2566.0  \n",
       "1       0       7       1        WD         Normal  2524.0  \n",
       "2       0      11       2        WD         Normal  2706.0  \n",
       "3       0       4       0        WD        Abnorml  2473.0  \n",
       "4       0       3       2        WD         Normal  3343.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['MSSubClass', 'OverallCond', 'YrSold', 'MoSold']\n",
    "for col in label_cols:\n",
    "    total_df[col] = total_df[col].astype(str)\n",
    "\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "for col in cols:\n",
    "    total_df[col] = LabelEncoder().fit_transform(total_df[col].values)\n",
    "\n",
    "total_df['TotalSF'] = total_df['TotalBsmtSF'] + total_df['1stFlrSF'] + total_df['2ndFlrSF'] \n",
    "\n",
    "print('Shape total df : {}' .format(total_df.shape))\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 221)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.get_dummies(total_df)\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = total_df[:len(train_label)]\n",
    "test_x = total_df[len(train_label):]\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "linear = LinearRegression(normalize = False, fit_intercept = True, copy_X = True)\n",
    "gdbt = GradientBoostingRegressor(tol=0.1, subsample=0.37, n_estimators=200, max_features=20, \n",
    "                                 max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestRegressor(n_estimators=300, min_samples_split=9, min_samples_leaf=10, \n",
    "                           max_features='sqrt', max_depth=8, bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "meta_estimator = GradientBoostingRegressor(tol = 10, subsample = 0.44, n_estimators = 100,\n",
    "                                          max_features = 'log2', max_depth = 4, learning_rate = 0.1)\n",
    "stacking = StackingRegressor(regressors = [linear, gdbt, rf], meta_regressor = meta_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(train_x, train_label)\n",
    "stacking_pred = stacking.predict(test_x)\n",
    "submission = pd.DataFrame({'Id' : test_ids , 'SalePrice' : np.expm1(stacking_pred)})\n",
    "submission.to_csv('house_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測\n",
    "分數以網站評分結果為準, 請同學實際將提交檔(*.csv)上傳試試看<br />\n",
    "https://www.kaggle.com/c/titanic/submit<br />\n",
    "\n",
    "\n",
    "## [作業目標]\n",
    "試著模仿範例寫法, 在鐵達尼生存預測中, 觀查堆疊泛化 (Stacking) 的寫法與效果<br />\n",
    "\n",
    "\n",
    "## [作業重點]\n",
    "完成堆疊泛化的寫作, 看看提交結果, 想想看 : 分類與回歸的堆疊泛化, 是不是也與混合泛化一樣有所不同呢?<br />\n",
    "如果可能不同, 應該怎麼改寫會有較好的結果?<br />\n",
    "Hint : 請參考 mlxtrend 官方網站 StackingClassifier 的頁面說明 : Using Probabilities as Meta-Features <br />http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_df = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "test_df = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_label = train_df.Survived\n",
    "test_ids = test_df.PassengerId\n",
    "\n",
    "train_df = train_df.drop(['Survived', 'PassengerId'], axis = 1)\n",
    "test_df = test_df.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "total_df = pd.concat([train_df,test_df], axis = 0)\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing ratio in Age : 20.091673032849503 %\n",
      " Missing ratio in Fare : 0.07639419404125286 %\n",
      " Missing ratio in Cabin : 77.46371275783041 %\n",
      " Missing ratio in Embarked : 0.15278838808250572 %\n"
     ]
    }
   ],
   "source": [
    "CheckMissingVals(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode female with 1 and male with 0\n",
    "#I think female might would had better change to survive, so I replace the female to 1 like a data trending.\n",
    "total_df['Sex'] = total_df['Sex'].map(lambda x : 1 if x == 'female' else 0)\n",
    "#Fare with very small portion of missing, I will simply replace the NA with median val\n",
    "total_df['Fare'] = total_df['Fare'].fillna(total_df['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              757\n",
       "Miss            260\n",
       "Mrs             197\n",
       "Master           61\n",
       "Rev               8\n",
       "Dr                8\n",
       "Col               4\n",
       "Mlle              2\n",
       "Ms                2\n",
       "Major             2\n",
       "Lady              1\n",
       "Sir               1\n",
       "Mme               1\n",
       "the Countess      1\n",
       "Jonkheer          1\n",
       "Capt              1\n",
       "Dona              1\n",
       "Don               1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Name column has some interesting infromation. \n",
    "#There are some titles in the names, like 'Mr', 'Mrs' and 'Master'... \n",
    "#This might be helpful for our data processing.\n",
    "\n",
    "total_df['Name'] = total_df['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n",
    "\n",
    "#Also we can change the column name with Title, since they are much like title now \n",
    "total_df = total_df.rename(columns = {'Name' : 'Title'})\n",
    "total_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we use google and some common knowledge to know the meaning of these titles. <br />\n",
    "Mr: Men which might be married or not.  <br />\n",
    "Miss: Women which are not married yet.  <br />\n",
    "Mrs: Women which are married.   <br />\n",
    "Master : Prestigious title  <br />\n",
    "Dr : might be doctor of professor <br />\n",
    "Rev : might be reverend  <br />\n",
    "Col : Boy Names  <br />\n",
    "Ms: title of respect of women.  <br />\n",
    "Major : might be some military rank  <br />\n",
    "Mlle : French girls  <br />\n",
    "the countess : respectful women title  <br />\n",
    "Sir : respectful men title  <br />\n",
    "Lady : respectful women title  <br />\n",
    "Capt : This must be captain(but we dont sure the gender)  <br />\n",
    "Jonkheer : respectful title  <br />\n",
    "Don : Im not sure, but I assume it is a male title  <br />\n",
    "Mme : Madame  <br />\n",
    "Dona : Im not sure, but I assume it is a female title  <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr         762\n",
       "Miss       263\n",
       "Mrs        197\n",
       "respect     87\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use above result to group title column\n",
    "total_df.Title.replace(to_replace = ['Dr','Major','Capt','Sir','Rev','Jonkheer','Master','Lady','Ms','Mme','the Countess'], value = 'respect', inplace = True)\n",
    "total_df.Title.replace(to_replace = ['Col','Don'], value = 'Mr', inplace = True)\n",
    "total_df.Title.replace(to_replace = ['Mlle','Dona'], value = 'Miss', inplace = True)\n",
    "\n",
    "#we can check the value_counts again after we group the title column\n",
    "total_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add few new features with SibSp and Parch features\n",
    "#The whole family size of a single data is SibSp+Parch+1, one for himself/herself\n",
    "\n",
    "total_df['Fsize'] = total_df['SibSp'] + total_df['Parch'] + 1\n",
    "total_df['Single'] = total_df['Fsize'].map(lambda x : 1 if x == 0 else 0)\n",
    "total_df['SmallF'] = total_df['Fsize'].map(lambda x : 1 if x == 2 else 0)\n",
    "total_df['MedF'] = total_df['Fsize'].map(lambda x : 1 if 3 <= x <= 4 else 0)\n",
    "total_df['LargeF'] = total_df['Fsize'].map(lambda x : 1 if x >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simply replace the data in ticket without letter with X and elimate the extra notions in the data for other data\n",
    "Ticket = []\n",
    "for i in list(total_df.Ticket):\n",
    "    if not i.isdigit():\n",
    "        Ticket.append(i.replace('.','').replace('/','').strip().split(' ')[0])\n",
    "    else:\n",
    "        Ticket.append('X')\n",
    "        \n",
    "total_df['Ticket'] = Ticket\n",
    "total_df = pd.get_dummies(total_df, columns = ['Ticket'], prefix = 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simply replace the missing values in Cabin with X, which means the person with no Cabin\n",
    "total_df['Cabin'] = total_df['Cabin'].fillna('X')\n",
    "#And replace the values with data`s first letter to represent the Cabin label\n",
    "total_df['Cabin'] = total_df['Cabin'].map(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding the Cabin\n",
    "total_df = pd.get_dummies(total_df, columns = ['Cabin'], prefix = 'Cabin_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somply replace the missing values in Embarked with mode val\n",
    "total_df['Embarked'] = total_df['Embarked'].fillna(total_df['Embarked'].mode()[0])\n",
    "#One hot encoding the Embarked\n",
    "total_df = pd.get_dummies(total_df, columns = ['Embarked'], prefix = 'Em_')\n",
    "\n",
    "#Turn the Pclass into object type\n",
    "total_df['Pclass'] = total_df['Pclass'].astype('category')\n",
    "total_df = pd.get_dummies(total_df, columns = ['Pclass'], prefix = \"Pc_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing ratio in Age : 20.091673032849503 %\n"
     ]
    }
   ],
   "source": [
    "CheckMissingVals(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age         1.000000\n",
      "Pc__1       0.393198\n",
      "Title       0.340346\n",
      "Pc__3       0.337069\n",
      "Cabin__X    0.289740\n",
      "SibSp       0.245152\n",
      "Fsize       0.240592\n",
      "T_PC        0.199506\n",
      "Fare        0.192608\n",
      "LargeF      0.178480\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#There are many missing values in Age data. So we could not simply fill the missing values with constant.\n",
    "#We can use the other columns to fill the missing values of Age data.\n",
    "#There are some columns might have large correaltion with Age, like title.\n",
    "#So we can calculate the correlation between Age and other features first.\n",
    "#But before that, we should turn the datas into numerical type first\n",
    "\n",
    "temp = copy.deepcopy(total_df[total_df.columns[total_df.columns != 'Age']])\n",
    "temp.Title.replace(to_replace = ['Mr'] , value = 0 , inplace = True)\n",
    "temp.Title.replace(to_replace = ['Mrs'] , value = 1 , inplace = True)\n",
    "temp.Title.replace(to_replace = ['Miss'] , value =  2, inplace = True)\n",
    "temp.Title.replace(to_replace = ['respect'] , value = 3 , inplace = True)\n",
    "temp = temp.agg(LabelEncoder().fit_transform)\n",
    "temp['Age'] = total_df['Age']   \n",
    "Corr = temp.corr()[\"Age\"].apply(lambda x : abs(x)).sort_values(ascending = False)\n",
    "print(Corr[:10])\n",
    "\n",
    "#Also since the missing values of age is filling by ourself. \n",
    "#We should add an extra columns to tell the model that there are some age data was missing.\n",
    "total_df['Missing_Age'] = total_df.Age.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above information, we can see that age column has larger correlation with 'Pclass' and 'Title'. \n",
    "#So I would like to use this column for missing filling of age.\n",
    "\n",
    "total_df.Age = temp.groupby(['Pc__1','Pc__3','Title'])['Age'].transform(lambda v: v.fillna(v.median()))\n",
    "CheckMissingVals(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0, 40.0]      738\n",
      "(-0.001, 20.0]    306\n",
      "(40.0, 60.0]      232\n",
      "(60.0, 80.0]       33\n",
      "Name: Age_Group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Also I would like to make a group for Age data\n",
    "cuttingArr = np.array([0,20,40,60,total_df.Age.max()])\n",
    "total_df['Age_Group'] = pd.cut(total_df.Age,cuttingArr,include_lowest = True)\n",
    "print(total_df.Age_Group.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>Single</th>\n",
       "      <th>SmallF</th>\n",
       "      <th>MedF</th>\n",
       "      <th>LargeF</th>\n",
       "      <th>...</th>\n",
       "      <th>Pc__3</th>\n",
       "      <th>Missing_Age</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_respect</th>\n",
       "      <th>AG_(-0.001, 20.0]</th>\n",
       "      <th>AG_(20.0, 40.0]</th>\n",
       "      <th>AG_(40.0, 60.0]</th>\n",
       "      <th>AG_(60.0, 80.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Age  SibSp  Parch     Fare  Fsize  Single  SmallF  MedF  LargeF  ...  \\\n",
       "0    0  22.0      1      0   7.2500      2       0       1     0       0  ...   \n",
       "1    1  38.0      1      0  71.2833      2       0       1     0       0  ...   \n",
       "2    1  26.0      0      0   7.9250      1       0       0     0       0  ...   \n",
       "3    1  35.0      1      0  53.1000      2       0       1     0       0  ...   \n",
       "4    0  35.0      0      0   8.0500      1       0       0     0       0  ...   \n",
       "\n",
       "   Pc__3  Missing_Age  Title_Miss  Title_Mr  Title_Mrs  Title_respect  \\\n",
       "0      1        False           0         1          0              0   \n",
       "1      0        False           0         0          1              0   \n",
       "2      1        False           1         0          0              0   \n",
       "3      0        False           0         0          1              0   \n",
       "4      1        False           0         1          0              0   \n",
       "\n",
       "   AG_(-0.001, 20.0]  AG_(20.0, 40.0]  AG_(40.0, 60.0]  AG_(60.0, 80.0]  \n",
       "0                  0                1                0                0  \n",
       "1                  0                1                0                0  \n",
       "2                  0                1                0                0  \n",
       "3                  0                1                0                0  \n",
       "4                  0                1                0                0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dont forget to one hot encoding the Title and Age Group features\n",
    "total_df = pd.get_dummies(total_df, columns = ['Title'], prefix = 'Title')\n",
    "total_df = pd.get_dummies(total_df, columns = ['Age_Group'], prefix = 'AG')\n",
    "\n",
    "total_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Missing_Age'] = total_df['Missing_Age'].map(lambda x : 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x5000 with 71 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#Here I want to see the data distribution by histogram\n",
    "ncols = 4\n",
    "nrows = len(total_df.columns) / ncols+1\n",
    "\n",
    "plt.figure(figsize = (25,50))\n",
    "for i,col in enumerate(total_df.columns):\n",
    "    if col != 'PassengerId' :\n",
    "        plt.subplot(nrows,ncols,i+1)\n",
    "        total_df[col].hist()\n",
    "        plt.title('histogram of %s' %col)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1309.000000\n",
       "mean        2.979226\n",
       "std         0.968321\n",
       "min         0.000000\n",
       "25%         2.185579\n",
       "50%         2.737881\n",
       "75%         3.474293\n",
       "max         6.240917\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixing the skewness of Fare feature\n",
    "total_df['Fare'] = np.log1p(total_df['Fare'])\n",
    "total_df.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = MinMaxScaler().fit_transform(total_df)\n",
    "\n",
    "train_x = total_df[:len(train_label)]\n",
    "test_x = total_df[len(train_label):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "#first we will tune the parameters of every model \n",
    "RFParams = {'n_estimators':np.arange(100,1100,50), 'max_depth':np.arange(3,11,2),\n",
    "            'min_samples_split':np.arange(2,20,2), 'min_samples_leaf':np.arange(1,6,2) }\n",
    "\n",
    "ETParams = {'n_estimators':np.arange(100,1100,50), 'max_depth':np.arange(3,11,2),\n",
    "            'min_samples_leaf':np.arange(1,6,2) }\n",
    "\n",
    "gbcParams = {'n_estimators' : np.arange(100,1100,50) , 'learning_rate' : np.arange(0.01,0.2,0.05) \n",
    "             , 'min_samples_split' : np.arange(2,20,2), 'min_samples_leaf' : np.arange(1,6,2),\n",
    "              'max_depth' : np.arange(3,11,2), 'subsample' : np.arange(0.3,0.8,0.1), 'max_features' : np.arange(10,30,5) }\n",
    "\n",
    "logParams = { 'C' : np.arange(0.1,1.5,0.2) }\n",
    "\n",
    "#We use GridSearchCV to find the best params of the classifier\n",
    "#cv = 5 means we will split data into 5 piece for cross validation.\n",
    "#n_jobs = -1 means we want all the processor to run in parallel (cuz this might take a lot of estimation)\n",
    "def tuneParams(classifier, params, train_x, train_y, cv = 5):\n",
    "    md = GridSearchCV(classifier, params, cv = cv, scoring = 'accuracy', n_jobs = -1)\n",
    "    md.fit(train_x,train_y)\n",
    "\n",
    "    return md.best_params_,np.round(md.best_score_*100,2)\n",
    "\n",
    "def tuneParamsRandom(classifier, params, train_x, train_y, cv=5):\n",
    "    rs = RandomizedSearchCV(classifier, params, n_iter = 30,scoring = 'accuracy', n_jobs = -1, verbose = 0)\n",
    "    rs.fit(train_x,train_y)\n",
    "    \n",
    "    return rs.best_params_, abs(rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: {'C': 1.3000000000000003} 0.8249158249158249\n",
      "GradientBoostingClassifier: {'subsample': 0.7000000000000002, 'n_estimators': 800, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 10, 'max_depth': 3, 'learning_rate': 0.060000000000000005} 0.8338945005611672\n",
      "RandomForest: {'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 5} 0.8282828282828283\n",
      "ExtraTrees: {'n_estimators': 950, 'min_samples_leaf': 1, 'max_depth': 5} 0.8305274971941639\n"
     ]
    }
   ],
   "source": [
    "# we will use xgboost, adaBoost, randomForest, ExtraTrees, KNeighbors and SVC to be the classifier of our first step ensemble stacking\n",
    "Log_best_Params, Log_best_score = tuneParamsRandom(LogisticRegression(tol = 0.001, fit_intercept = True), logParams, train_x, train_label)\n",
    "print(\"LogisticRegression:\",Log_best_Params,Log_best_score)\n",
    "\n",
    "GBC_best_Params,GBC_best_score = tuneParamsRandom(GradientBoostingClassifier(),gbcParams,train_x,train_label)\n",
    "print(\"GradientBoostingClassifier:\",GBC_best_Params,GBC_best_score)\n",
    "\n",
    "RF_best_Params,RF_best_score = tuneParamsRandom(RandomForestClassifier(),RFParams,train_x,train_label)\n",
    "print(\"RandomForest:\",RF_best_Params,RF_best_score)\n",
    "\n",
    "ET_best_Params,ET_best_score = tuneParamsRandom(ExtraTreesClassifier(),ETParams,train_x,train_label)\n",
    "print(\"ExtraTrees:\",ET_best_Params,ET_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(**Log_best_Params)\n",
    "gbc = GradientBoostingClassifier(**GBC_best_Params)\n",
    "rf = RandomForestClassifier(**RF_best_Params)\n",
    "et = ExtraTreesClassifier(**ET_best_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "分類預測的集成泛化, 也與回歸的很不一樣\n",
    "既然分類的 Blending 要變成機率, 才比較容易集成, 那麼分類的 Stacking 要讓第一層的模型輸出機率當特徵, 應該要怎麼寫呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im gonna do the stacking without mlxtend module\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = 2019)\n",
    "n_train = len(train_x)\n",
    "n_test = len(test_x)\n",
    "def FoldTraining(clf, train_x, train_y, test_x):\n",
    "    #get out-of-fold predictions for a given model\n",
    "    oof_train = np.zeros((n_train))\n",
    "    oof_test = np.zeros((n_test))\n",
    "    oof_kf_test = np.zeros((5, n_test))\n",
    "    \n",
    "    for i,(train_idx, test_idx) in enumerate(kf.split(train_x)):\n",
    "        kf_train_x = train_x[train_idx,:]\n",
    "        kf_train_y = train_y[train_idx]\n",
    "        kf_test_x = train_x[test_idx,:]\n",
    "        \n",
    "        clf.fit(kf_train_x, kf_train_y)\n",
    "        \n",
    "        oof_train[test_idx] = clf.predict_proba(kf_test_x)[:,1]\n",
    "        oof_kf_test[i,:] = clf.predict_proba(test_x)[:,1]\n",
    "    oof_test = oof_kf_test.mean(axis = 0)\n",
    "    \n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_oof_train, log_oof_test = FoldTraining(log, train_x, train_label, test_x)\n",
    "gbc_oof_train, gbc_oof_test = FoldTraining(gbc, train_x, train_label, test_x)\n",
    "rf_oof_train, rf_oof_test = FoldTraining(rf, train_x, train_label, test_x)\n",
    "et_oof_train, et_oof_test = FoldTraining(et, train_x, train_label, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " meta estimator : {'subsample': 0.6000000000000001, 'n_estimators': 500, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 3, 'max_depth': 3, 'learning_rate': 0.01}, 0.8103254769921436 \n"
     ]
    }
   ],
   "source": [
    "gbcParams = {'n_estimators' : np.arange(100,1100,50) , 'learning_rate' : np.arange(0.01,0.2,0.05) \n",
    "             , 'min_samples_split' : np.arange(2,20,2), 'min_samples_leaf' : np.arange(1,6,2),\n",
    "              'max_depth' : np.arange(3,11,2), 'subsample' : np.arange(0.3,0.8,0.1), 'max_features' : np.arange(2,4,1) }\n",
    "\n",
    "classifiers = ['log','gbc','rf','et']\n",
    "final_train = pd.DataFrame(np.concatenate((log_oof_train, gbc_oof_train, rf_oof_train, et_oof_train), axis = 1) , columns = classifiers)\n",
    "final_test = pd.DataFrame(np.concatenate((log_oof_test, gbc_oof_test, rf_oof_test, et_oof_test), axis = 1) , columns = classifiers)\n",
    "\n",
    "meta_estimator_param, meta_estimaotr_score = tuneParamsRandom(gbc, gbcParams, final_train, train_label)\n",
    "print(f' meta estimator : {meta_estimator_param}, {meta_estimaotr_score} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10509395, 0.6110145 , 0.07919744, 0.07119495, 0.49542798,\n",
       "       0.09644956, 0.46710407, 0.08304335, 0.81715326, 0.06645499])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.set_params(**meta_estimator_param)\n",
    "gbc.fit(final_train, train_label)\n",
    "\n",
    "final_pred = gbc.predict_proba(final_test)[:,1]\n",
    "final_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId' : test_ids, 'Survived' : final_pred})\n",
    "submission['Survived'] = submission['Survived'].map(lambda x : 0 if x <0.5 else 1)\n",
    "submission.to_csv('titanic_stacking.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
