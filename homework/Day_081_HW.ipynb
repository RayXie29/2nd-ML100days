{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例重點\n",
    "了解如何在 Keras 中，加入 regularization <br />\n",
    "熟悉建立、訓練模型 <br />\n",
    "熟悉將訓練結果視覺化並比較結果 <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_x(x, flatten = True):\n",
    "    x = x / 255.0\n",
    "    if flatten :\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes = 10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = preproc_x(train_x)\n",
    "test_x = preproc_x(test_x)\n",
    "train_y = preproc_y(train_y)\n",
    "test_y = preproc_y(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "def build_mlp(input_shape, output_units = 10, num_neurons = [512, 256, 128], l2_ratio = 1e-4):\n",
    "    \n",
    "    input_layer = Input(input_shape, name = \"main_input\")\n",
    "    \n",
    "    for i , n_units in enumerate(num_neurons):\n",
    "        \n",
    "        if i == 0 :\n",
    "            x = Dense(units = n_units, activation = 'relu', name = \"hidden_layer\" + str(i+1),\n",
    "                             kernel_regularizer = l2(l2_ratio)) (input_layer)\n",
    "        else:\n",
    "            x = Dense(units = n_units, activation = 'relu', name = \"hidden_layer\" + str(i+1),\n",
    "                             kernel_regularizer = l2(l2_ratio)) (x)\n",
    "        \n",
    "    output_layer = Dense(units = output_units, activation = 'softmax', name = \"main_output\") (x)\n",
    "    \n",
    "    model = keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting hyper-parameters\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "momentum = 0.95\n",
    "l2_exp = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for regulizer_ratio in l2_exp:\n",
    "    keras.backend.clear_session()\n",
    "    print(f\"Experiment with regulizer : {regulizer_ratio}\")\n",
    "    model = build_mlp(input_shape = train_x.shape[1:], l2_ratio = regulizer_ratio)\n",
    "    optimizer = keras.optimizers.Adam(lr = lr)\n",
    "    model.compile( optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    history = model.fit(train_x, train_y, epochs = epochs, batch_size = batch_size, shuffle = True, validation_data = [test_x, test_y])\n",
    "    \n",
    "    name_tag = f\"regulizer_{str(regulizer)}\"\n",
    "    results[name_tag] = {\n",
    "        'train_loss' : history.history['loss'],\n",
    "        'valid_loss' : history.history['val_loss'],\n",
    "        'train_acc' : history.history['acc'],\n",
    "        'valid_acc' : history.history['val_acc']\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['r','g','b','y','k','m']\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(results[cond]['train_loss'], '-', label = cond + \"_train\", color = colors[i])\n",
    "    plt.plot(results[cond]['valid_loss'], '--', label = cond + \"_valid\", color = colors[i])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(results[cond]['train_acc'], '-', label = cond + '_train', color = colors[i])\n",
    "    plt.plot(results[cond]['valid_acc'], '--',label = cond + '_valid', color = colors[i])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work\n",
    "請比較使用 l1, l1_l2 及不同比例下的訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_x = preproc_x(train_x, False)\n",
    "test_x = preproc_x(train_x, False)\n",
    "train_y = preproc_y(train_y)\n",
    "test_y = preproc_y(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Dropout, BatchNormalization, MaxPooling2D\n",
    "\n",
    "def build_mlp2(input_shape, output_units = 10, regularizer = None):\n",
    "    \n",
    "    input_layer = Input(input_shape, name = \"main_input\")\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_regularizer = regularizer)(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling(pool_size = (2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling(pool_size = (2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units = 512, activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = Dense(units = 256, activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = Dense(units = 128, activation = 'relu', kernel_regularizer = regularizer)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    output_layer = Dense(units = output_units, activation = 'softmax', name = \"main_output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting hyper-parameters\n",
    "lr = 1e-3\n",
    "regs = ['l1','l1_l2']\n",
    "reg_ratios = [1e-4, 1e-6, 1e-8]\n",
    "epochs = 30\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for reg in regs:\n",
    "    for reg_ratio in reg_ratios:\n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "        print(f\"{str(reg)} regularizer with {reg_ratio} regular ratio\")\n",
    "        cur_reg = None\n",
    "        if reg == 'l1':\n",
    "            cur_reg = l1(reg_ratio)\n",
    "        else:\n",
    "            cur_reg = l1_l2(l1 = reg_ratio, l2 = reg_ratio)\n",
    "            \n",
    "        model = build_mlp2(input_shape = train_x.shape[1:],regularizer = cur_reg)\n",
    "        optimizer = keras.optimizers.Adam(lr = lr)\n",
    "        model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "        \n",
    "        history = model. fit(train_x, train_y, epochs = epochs, batch_size = batch_size, shuffle = True, validation_data = [test_x,test_y])\n",
    "        \n",
    "        name_tag = f\"regulizer_{str(regulizer)}\"\n",
    "        results[name_tag] = {\n",
    "        'train_loss' : history.history['loss'],\n",
    "        'valid_loss' : history.history['val_loss'],\n",
    "        'train_acc' : history.history['acc'],\n",
    "        'valid_acc' : history.history['val_acc']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r','g','b','y','k','m']\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(results[cond]['train_loss'], '-', label = cond + \"_train\", color = colors[i])\n",
    "    plt.plot(results[cond]['valid_loss'], '--', label = cond + \"_valid\", color = colors[i])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(results[cond]['train_acc'], '-', label = cond + '_train', color = colors[i])\n",
    "    plt.plot(results[cond]['valid_acc'], '--',label = cond + '_valid', color = colors[i])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
