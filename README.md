# 2nd-ML100days
<br /><br />

## 1-資料清理數據前處理

<br />
D1：資料介紹與評估資料<br />
D2：EDA-1/讀取資料EDA: Data summary<br />
D3：3-1如何新建一個 dataframe?3-2 如何讀取其他資料? (非 csv 的資料)<br />
D4：EDA: 欄位的資料類型介紹及處理<br />
D5：EDA資料分佈<br />
D6：EDA: Outlier 及處理<br />
D7：常用的數值取代：中位數與分位數連續數值標準化<br />
D8：DataFrame operationData frame merge/常用的 DataFrame 操作<br />
D9：程式實作 EDA: correlation/相關係數簡介<br />
D10：EDA from Correlation<br />
D11：EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)<br />
D12：EDA: 把連續型變數離散化<br />
D13：程式實作 把連續型變數離散化<br />
D14：Subplots<br />
D15：Heatmap & Grid-plot<br />
D16：模型初體驗 Logistic Regression<br />
<br /><br />

## 2-資料科學特徵工程技術

<br />
D17：特徵工程簡介<br />
D18：特徵類型<br />
D19：數值型特徵-補缺失值與標準化<br />
D20：數值型特徵 - 去除離群值<br />
D21：數值型特徵 - 去除偏態<br />
D22：類別型特徵 - 基礎處理<br />
D23：類別型特徵 - 均值編碼<br />
D24：類別型特徵 - 其他進階處理<br />
D25：時間型特徵<br />
D26：特徵組合 - 數值與數值組合<br />
D27：特徵組合 - 類別與數值組合<br />
D28：特徵選擇<br />
D29：特徵評估<br />
D30：分類型特徵優化 - 葉編碼<br />
<br /><br />

## 3-機器學習基礎模型建立

<br /><br />
D31：機器學習概論<br />
D32：機器學習-流程與步驟<br />
D33：機器如何學習?<br />
D34：訓練/測試集切分的概念<br />
D35：regression vs. classification<br />
D36：評估指標選定/evaluation metrics<br />
D37：regression model 介紹 - 線性迴歸/羅吉斯回歸<br />
D38：regression model 程式碼撰寫<br />
D39：regression model 介紹 - LASSO 回歸/ Ridge 回歸<br />
D40：regression model 程式碼撰寫 <br />
D41：tree based model - 決策樹 (Decision Tree) 模型介紹<br />
D42：tree based model - 決策樹程式碼撰寫<br />
D43：tree based model - 隨機森林 (Random Forest) 介紹<br />
D44：tree based model - 隨機森林程式碼撰寫<br />
D45：tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹 <br />
D46：tree based model - 梯度提升機程式碼撰寫<br />
<br /><br />
## 4-機器學習調整參數
<br /><br />
D47：超參數調整與優化<br />
D48：Kaggle 競賽平台介紹<br />
D49：集成方法 : 混合泛化(Blending) <br />
D50：集成方法 : 堆疊泛化(Stacking) <br />
D51-D53 : Mid-term exam : Kaggle competition - Coupon usage prediction <br />
<br /><br />
## 5-非監督式機器學習
<br /><br />
D54：clustering 1 非監督式機器學習簡介 <br />
D55：clustering 2 聚類算法 <br />
D56：K-mean 觀察 : 使用輪廓分析 <br />
D57：clustering 3 階層分群算法 <br />
D58：階層分群法 觀察 : 使用 2D 樣版資料集 <br />
D59：dimension reduction 1 降維方法-主成份分析 <br />
D60：PCA 觀察 : 使用手寫辨識資料集 <br />
D61：dimension reduction 2 降維方法-T-SNE <br />
D62：t-sne 觀察 : 分群與流形還原 <br />
<br /><br />
## 6-深度學習理論與實作
<br /><br />
D63：神經網路介紹 <br />
D64：深度學習體驗 : 模型調整與學習曲線 <br />
D65：深度學習體驗 : 啟動函數與正規化 <br />
<br /><br />
## 7-初探深度學習使用 Keras
<br /><br />
D66：Keras 安裝與介紹 <br />
D67：Keras Dataset <br />
D68：Keras Sequential API <br />
D69：Keras Module API <br />
D70：Multi-layer Perception多層感知 <br />
D71：損失函數 <br />
D72：啟動函數 <br />
D73：梯度下降Gradient Descent <br />
D74：Gradient Descent 數學原理 <br />
D75：BackPropagation <br />
D76：優化器optimizers <br />
D77：訓練神經網路的細節與技巧 - Validation and overfit <br />
D78：訓練神經網路前的注意事項 <br />
D79：訓練神經網路的細節與技巧 - Learning rate effect <br />
D80：[練習 Day] 優化器與學習率的組合與比較 <br />
D81：訓練神經網路的細節與技巧 - Regularization <br />
D82：訓練神經網路的細節與技巧 - Dropout <br />
D83：訓練神經網路的細節與技巧 - Batch normalization <br />
D84：[練習 Day] 正規化/機移除/批次標準化的 組合與比較 <br />
D85：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop <br />
D86：訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model <br />
D87：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate <br />
D88：訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數 <br />
D89：訓練神經網路的細節與技巧 - 撰寫自己的 Loss function <br />
D90：使用傳統電腦視覺與機器學習進行影像辨識 <br />
D91：[練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識 <br />
<br /><br />
## 8-深度學習應用卷積神經網路
<br /><br />

D92：卷積神經網路 (Convolution Neural Network, CNN) 簡介 <br />
D93：卷積神經網路架構細節 <br />
D94：卷積神經網路 - 卷積(Convolution)層與參數調整 <br />
D95：卷積神經網路 - 池化(Pooling)層與參數調整 <br />
D96：Keras 中的 CNN layers <br />
D97：使用 CNN 完成 CIFAR-10 資料集 <br />
D98：訓練卷積神經網路的細節與技巧 - 處理大量數據 <br />
D99：訓練卷積神經網路的細節與技巧 - 處理小量數據 <br />
D100：訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning) <br />

D101-D103 : final exam : Kaggle competition - Dogs and cats classification <br />

